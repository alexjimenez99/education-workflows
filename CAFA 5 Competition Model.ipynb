{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.session                 import s3_input, Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'cafaprotein'\n",
    "my_region   = boto3.session.Session().region_name\n",
    "print(my_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create a bucket**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 = boto3.resource('s3')\n",
    "# try:\n",
    "#     if my_region == 'us-east-1':\n",
    "#         s3.create_bucket(Bucket = bucket_name)\n",
    "#     print('S3 Bucket Created')\n",
    "# except Exception as e:\n",
    "#     print('S3 Error: ', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Files from S3 Bucket**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dload_client =  boto3.client('s3')\n",
    "# cafa_file    = './cafa-5-protein-function-prediction.zip'\n",
    "# dload_client.download_file(bucket_name, 'cafa-5-protein-function-prediction.zip', \n",
    "#                                                                         cafa_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrieve Files from s3**\n",
    "1. Fun OSError may have to expand the local s3 space to work in this notebook\n",
    "2. SSH key Passphrase and GITHUB Secret Key: Y5d7fp32!@\n",
    "3. SSH Key GITHUB: SHA256:KFfeCtQipma5pu6OqX3BMrtckwIjZqqg6HvtqN7fdiI alexxaeljimenez@gmail.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git add cafa-5-protein-function-prediction.zip labels_df.pckl cafa_train_test_embeddings.zip\n",
    "# !git commit -m \"Adding Cafa Files to GitHub Repository\"\n",
    "# !git push\n",
    "\n",
    "# !killall ssh-agent\n",
    "# !eval \"$(ssh-agent -s)\"\n",
    "# !ssh-add /home/ec2-user/.ssh/id_rsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Files From S3 Bucket \n",
    "def load_s3_files(file_names, relative_paths):\n",
    "    dload_client =  boto3.client('s3')\n",
    "\n",
    "    for index, file_name in enumerate(file_names):\n",
    "\n",
    "        dload_client.download_file(bucket_name, file_name, relative_paths[index])\n",
    "        \n",
    "        print(relative_paths[index])\n",
    "        \n",
    "    return None\n",
    "\n",
    "\n",
    "file_names     = ['protein_seq.pckl', \n",
    "                 'ontology_dict.pckl', \n",
    "                 'cafa_train_test_embeddings.zip', \n",
    "                 'train_labels.pckl',\n",
    "                 'test_labels.pckl']\n",
    "\n",
    "relative_paths = ['./protein_seq.pckl',\n",
    "                 './ontology_dict.pckl',\n",
    "                 './cafa_train_test_embeddings.zip',\n",
    "                 './labels_df.pckl',\n",
    "                 './test_labels.pckl']\n",
    "\n",
    "\n",
    "# load_s3_files(file_names, relative_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upload file to s3 Bucket**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def upload_s3_file(file_name):\n",
    "    \n",
    "#     file_name = file_name\n",
    "    \n",
    "#     return\n",
    "\n",
    "s3        = boto3.resource('s3')\n",
    "# # file_name = 't5embeds.zip'\n",
    "# # y_train   = 'labels_df.pckl'\n",
    "# s3.meta.client.upload_file('test_labels2.h5', bucket_name, 'test_labels.h5')\n",
    "# s3.meta.client.upload_file('labels_df.h5',   bucket_name, 'labels_df.h5')\n",
    "\n",
    "# s3.meta.client.upload_file('train_labels.h5', bucket_name, 'train_labels.h5')\n",
    "# s3.meta.client.upload_file('test_labels.h5', bucket_name, 'test_labels.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jg6bgN94UpCr"
   },
   "source": [
    "**Competition Goal**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "The goal of this competition is to predict the function of a set of proteins. You will develop a model trained on the amino-acid sequences of the proteins and on other data. Your work will help ​​researchers better understand the function of proteins, which is important for discovering how cells, tissues, and organs work. This may also aid in the development of new drugs and therapies for various diseases.\n",
    "\n",
    "1. Derive Function from the datasets from amino acid sequences\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAr_USzk9XMW"
   },
   "source": [
    "**Load Kaggle.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.16.tar.gz (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from kaggle) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from kaggle) (2.29.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from kaggle) (4.65.0)\n",
      "Requirement already satisfied: python-slugify in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from kaggle) (8.0.1)\n",
      "Requirement already satisfied: urllib3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from kaggle) (1.26.14)\n",
      "Requirement already satisfied: bleach in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from kaggle) (6.0.0)\n",
      "Requirement already satisfied: webencodings in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->kaggle) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->kaggle) (3.4)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.16-py3-none-any.whl size=110685 sha256=6fa4c4529a3c084a877e7aa14f3abdfe534a9f1d5af2ba769e668fd300c9bfac\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/43/4b/fb/736478af5e8004810081a06259f9aa2f7c3329fc5d03c2c412\n",
      "Successfully built kaggle\n",
      "Installing collected packages: kaggle\n",
      "Successfully installed kaggle-1.5.16\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Os2sPNGQ9XMY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mkdir ~/.kaggle\n",
    "# !touch ~/.kaggle/kaggle.json\n",
    "\n",
    "# api_token = {\"username\":\"alji1305\",\"key\":\"4703b0a6c6a8543e51a6de4131ab05cb\"}\n",
    "\n",
    "# import json\n",
    "# with open('kaggle/kaggle.json', 'w') as file:\n",
    "#     json.dump(api_token, file)\n",
    "\n",
    "# !chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmDTYlVc9XMZ"
   },
   "source": [
    "**Package Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "968SInTH9XMc",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !apt install libgraphviz-dev\n",
    "# !pip install pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_A_rOQw9XMd",
    "outputId": "e07bd362-2ae5-4f9d-fd32-9e3ca2b63c1c"
   },
   "outputs": [],
   "source": [
    "# !pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "2hZxGgdbU0Wi",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "c41ab7af-c94d-4bc1-8d49-a045c51270c0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting tensorflow==2.8.0\n",
      "  Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=0.4.0 (from tensorflow==2.8.0)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0 (from tensorflow==2.8.0)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=1.12 (from tensorflow==2.8.0)\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast>=0.2.1 (from tensorflow==2.8.0)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow==2.8.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow==2.8.0) (3.8.0)\n",
      "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.8.0)\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=9.0.1 (from tensorflow==2.8.0)\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow==2.8.0) (1.22.3)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.8.0)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow==2.8.0) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow==2.8.0) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow==2.8.0) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.8.0)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow==2.8.0) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow==2.8.0) (1.15.0)\n",
      "Collecting tensorboard<2.9,>=2.8 (from tensorflow==2.8.0)\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m140.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8.0)\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.0)\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.8.0)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.33.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3 (from tensorflow==2.8.0)\n",
      "  Downloading grpcio-1.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.40.0)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
      "  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.8/181.8 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.29.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m125.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.3.4)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.7.2)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.26.14)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.5.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tf-estimator-nightly, tensorboard-plugin-wit, libclang, keras, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, pyasn1-modules, opt-einsum, oauthlib, markdown, keras-preprocessing, grpcio, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.57.0 keras-2.8.0 keras-preprocessing-1.1.2 libclang-16.0.6 markdown-3.4.4 oauthlib-3.2.2 opt-einsum-3.3.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.33.0 termcolor-2.3.0 tf-estimator-nightly-2.8.0.dev2021122109\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting pronto\n",
      "  Downloading pronto-2.5.5-py2.py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: chardet~=5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pronto) (5.1.0)\n",
      "Collecting fastobo~=0.12.2 (from pronto)\n",
      "  Downloading fastobo-0.12.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx<4.0,>=2.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pronto) (3.1)\n",
      "Requirement already satisfied: python-dateutil~=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pronto) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil~=2.8->pronto) (1.16.0)\n",
      "Installing collected packages: fastobo, pronto\n",
      "Successfully installed fastobo-0.12.2 pronto-2.5.5\n"
     ]
    }
   ],
   "source": [
    "!pip install pronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting progressbar\n",
      "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: progressbar\n",
      "  Building wheel for progressbar (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12067 sha256=c1ad16d29253b891e98ad900bba4f00f72dd761d4f0e83897936a05289ea9256\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/cd/17/e5/765d1a3112ff3978f70223502f6047e06c43a24d7c5f8ff95b\n",
      "Successfully built progressbar\n",
      "Installing collected packages: progressbar\n",
      "Successfully installed progressbar-2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting bayesian-optimization==1.4.0\n",
      "  Downloading bayesian_optimization-1.4.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from bayesian-optimization==1.4.0) (1.22.3)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from bayesian-optimization==1.4.0) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from bayesian-optimization==1.4.0) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn>=0.18.0->bayesian-optimization==1.4.0) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn>=0.18.0->bayesian-optimization==1.4.0) (3.1.0)\n",
      "Installing collected packages: bayesian-optimization\n",
      "Successfully installed bayesian-optimization-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install bayesian-optimization==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: colorama 0.4.4\n",
      "Uninstalling colorama-0.4.4:\n",
      "  Successfully uninstalled colorama-0.4.4\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting colorama==0.4.3\n",
      "  Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
      "Installing collected packages: colorama\n",
      "Successfully installed colorama-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall colorama -y\n",
    "!pip install colorama==0.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WoIvwZ3T9XMe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy      as np\n",
    "import pandas     as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn    as sns\n",
    "from   zipfile    import ZipFile\n",
    "from   datetime   import datetime\n",
    "import random\n",
    "import re\n",
    "import pronto\n",
    "import fastobo\n",
    "import networkx\n",
    "import progressbar\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import seaborn    as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection         import KFold\n",
    "from sklearn.preprocessing           import OneHotEncoder\n",
    "from tensorflow.keras.optimizers     import Adam\n",
    "from sagemaker.remote_function       import remote\n",
    "from bayes_opt                       import BayesianOptimization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWC0mkVS9XMe",
    "outputId": "b22e3ae3-59d9-46bc-ad32-92b5748e9aae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !kaggle competitions download -c cafa-5-protein-function-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d sergeifironov/t5embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtLB-sYC9XMf"
   },
   "source": [
    "**Opening Files**\n",
    "1. Fasta format has two categories: description and sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sXudbRlx9XMf",
    "outputId": "6cb436d8-49dc-4ebb-bd54-e7b8ea7eb237",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IA.txt', 'Test (Targets)/testsuperset-taxon-list.tsv', 'Test (Targets)/testsuperset.fasta', 'Train/go-basic.obo', 'Train/train_sequences.fasta', 'Train/train_taxonomy.tsv', 'Train/train_terms.tsv', 'sample_submission.tsv']\n"
     ]
    }
   ],
   "source": [
    "with ZipFile('cafa-5-protein-function-prediction.zip') as zip:\n",
    "    print(zip.namelist())\n",
    "    with zip.open(zip.namelist()[0], 'r') as file:\n",
    "        IA                = file.readlines()\n",
    "    with zip.open(zip.namelist()[1], 'r') as file:\n",
    "        test_superset     = pd.read_csv(file, sep = '\\t', encoding='latin1')\n",
    "    with zip.open(zip.namelist()[2], 'r') as fasta:\n",
    "        test_fasta        = fasta.readlines()\n",
    "    with zip.open(zip.namelist()[3], 'r') as obo:\n",
    "        #ontology_text = obo.read()\n",
    "        gene_ontology     = pronto.Ontology(obo)\n",
    "    with zip.open(zip.namelist()[4], 'r') as fasta:\n",
    "        train_fasta       = fasta.readlines()\n",
    "\n",
    "    # Taxonomy Contains EntryID Uniprot DB and Taxonomy ID (Species Specific ID)\n",
    "    with zip.open(zip.namelist()[5], 'r') as file:   \n",
    "        train_taxonomy    = pd.read_csv(file, sep = '\\t')\n",
    "\n",
    "    # Train Terms EntryID, GO term #, and Aspect (3 Unique)\n",
    "    with zip.open(zip.namelist()[6], 'r') as file:\n",
    "        train_terms       = pd.read_csv(file, sep = '\\t')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eX4hx5id9XMh"
   },
   "source": [
    "**Bytes to String**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pMYJUUkx9XMh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_fasta  = [line.decode() for line in test_fasta]\n",
    "train_fasta = [line.decode() for line in train_fasta]\n",
    "IA          = [line.decode() for line in IA]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsMzesPt6SD5"
   },
   "source": [
    "**Parse IA File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6_g3g0wf6ZJE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ia_file          = re.compile('(GO.*)\\\\t(\\d+.\\d+)\\\\n')  # Majority of Entries\n",
    "GO_clean         = re.compile('(GO.*)(d+.\\d+)')         # Some Entries Just have Tabs and \\n \n",
    "                                                        # Actually executed so it's not in the text\n",
    "patterns         = []\n",
    "patterns2        = []\n",
    "IA_df            = {}\n",
    "for item in IA:\n",
    "  IA_file        = ia_file.findall(item)\n",
    "  GO_id          = IA_file[0][0]  \n",
    "  IA_df[GO_id]   = IA_file[0][1]  \n",
    "  patterns2.append(IA_file)\n",
    "\n",
    "IA_df = pd.DataFrame.from_dict(IA_df, orient = 'index', columns = ['Information Accreation'])\n",
    "IA_df = IA_df.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7qkhOyv9XMi"
   },
   "source": [
    "**Read Fasta Files into Dictionary Format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Py0f-Zf79XMj",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_fasta(fasta_file):\n",
    "    genes        = {}\n",
    "    id_pattern   = re.compile('>(.*)\\n')\n",
    "    gene_pattern = re.compile('^(\\w+)')\n",
    "    for line in fasta_file:\n",
    "        if len(id_pattern.findall(line))!= 0:\n",
    "            id_gene        = id_pattern.findall(line)[0]\n",
    "            genes[id_gene] = ''\n",
    "        else:\n",
    "            if len(gene_pattern.findall(line)) != 0:\n",
    "                genes[id_gene] += gene_pattern.findall(line)[0]\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    return genes\n",
    "\n",
    "train_fasta_dict  = read_fasta(train_fasta)\n",
    "test_fasta_dic    = read_fasta(test_fasta)\n",
    "\n",
    "# Remove \\t and \\r in the text\n",
    "test_fasta_dict     = {}\n",
    "for id in test_fasta_dic.keys():\n",
    "  original_id = id\n",
    "  id          = id.replace('\\t', ' ')\n",
    "  id          = id.replace('\\r', '')\n",
    "  test_fasta_dict[id] = test_fasta_dic[original_id] \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes the ID from the rest of the protein description\n",
    "def extract_protein_labels(protein_labels):\n",
    "    \n",
    "    first_word  = re.compile(r'^(\\w+)')\n",
    "    test_labels = [first_word.findall(key)[0] for key in protein_labels.keys()]\n",
    "    \n",
    "    return test_labels\n",
    "\n",
    "protein_test_labels  = extract_protein_labels(test_fasta_dict)\n",
    "protein_train_labels = extract_protein_labels(train_fasta_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGvC4TJcEnNG"
   },
   "source": [
    "**Test Fasta Dict**\n",
    "1. Keys contain taxaonmy label and uniprot protein ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "oja5w_aE05Vy",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryID</th>\n",
       "      <th>taxonomyID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q8IXT2</td>\n",
       "      <td>9606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q04418</td>\n",
       "      <td>559292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A8DYA3</td>\n",
       "      <td>7227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q9UUI3</td>\n",
       "      <td>284812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q57ZS4</td>\n",
       "      <td>185431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142241</th>\n",
       "      <td>Q5TD07</td>\n",
       "      <td>9606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142242</th>\n",
       "      <td>A8BB17</td>\n",
       "      <td>7955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142243</th>\n",
       "      <td>A0A2R8QBB1</td>\n",
       "      <td>7955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142244</th>\n",
       "      <td>P0CT72</td>\n",
       "      <td>284812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142245</th>\n",
       "      <td>Q9NZ43</td>\n",
       "      <td>9606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142246 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           EntryID  taxonomyID\n",
       "0           Q8IXT2        9606\n",
       "1           Q04418      559292\n",
       "2           A8DYA3        7227\n",
       "3           Q9UUI3      284812\n",
       "4           Q57ZS4      185431\n",
       "...            ...         ...\n",
       "142241      Q5TD07        9606\n",
       "142242      A8BB17        7955\n",
       "142243  A0A2R8QBB1        7955\n",
       "142244      P0CT72      284812\n",
       "142245      Q9NZ43        9606\n",
       "\n",
       "[142246 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "RzcnosMFsyLg",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryID</th>\n",
       "      <th>term</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A009IHW8</td>\n",
       "      <td>GO:0008152</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A009IHW8</td>\n",
       "      <td>GO:0034655</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A009IHW8</td>\n",
       "      <td>GO:0072523</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A009IHW8</td>\n",
       "      <td>GO:0044270</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A009IHW8</td>\n",
       "      <td>GO:0006753</td>\n",
       "      <td>BPO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363858</th>\n",
       "      <td>X5L565</td>\n",
       "      <td>GO:0050649</td>\n",
       "      <td>MFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363859</th>\n",
       "      <td>X5L565</td>\n",
       "      <td>GO:0016491</td>\n",
       "      <td>MFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363860</th>\n",
       "      <td>X5M5N0</td>\n",
       "      <td>GO:0005515</td>\n",
       "      <td>MFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363861</th>\n",
       "      <td>X5M5N0</td>\n",
       "      <td>GO:0005488</td>\n",
       "      <td>MFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363862</th>\n",
       "      <td>X5M5N0</td>\n",
       "      <td>GO:0003674</td>\n",
       "      <td>MFO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5363863 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            EntryID        term aspect\n",
       "0        A0A009IHW8  GO:0008152    BPO\n",
       "1        A0A009IHW8  GO:0034655    BPO\n",
       "2        A0A009IHW8  GO:0072523    BPO\n",
       "3        A0A009IHW8  GO:0044270    BPO\n",
       "4        A0A009IHW8  GO:0006753    BPO\n",
       "...             ...         ...    ...\n",
       "5363858      X5L565  GO:0050649    MFO\n",
       "5363859      X5L565  GO:0016491    MFO\n",
       "5363860      X5M5N0  GO:0005515    MFO\n",
       "5363861      X5M5N0  GO:0005488    MFO\n",
       "5363862      X5M5N0  GO:0003674    MFO\n",
       "\n",
       "[5363863 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cILP-uSHWoh"
   },
   "source": [
    "**Section 1 Summary**\n",
    "1. ~ 140,000 Unique Proteins with their associated Fasta sequences\n",
    "2. ~ 31466   Unique Gene Ontology (GO) Codes \n",
    "3. ~ 3156    Taxonomy IDs (Different Organisms)\n",
    "4. IA -- Information Accretion, basically a measure of how much new relevant information is added by each Gene Ontology (GO) code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPaVu_md1I2r"
   },
   "source": [
    "# Section 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kq9gAol4lau"
   },
   "source": [
    "**Gene Ontology (GO) Codes Are Not Unique**\n",
    "1. Tyrosine Kinase Inhibition could be a GO code, where multiple proteins could take on that behavior\n",
    "3. Unknown information about protein interactions can be a source for error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "qXyAkKW01Uh7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "gene_ont_counts = train_terms['term'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJ6YJHJzzvXI",
    "outputId": "bdd8162d-a76a-4bee-a156-b3c37cfac6d0",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "term\n",
       "GO:0005575    92912\n",
       "GO:0008150    92210\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_terms[train_terms.groupby('term')['term'].transform('size') > 92000]['term'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ih3nbAg9XMj"
   },
   "source": [
    "**Pattern at Beginning of Description**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CMNgcd2EsoO"
   },
   "source": [
    "1. BPO: Biological Process Ontology\n",
    "2. CCO: Cellular Componenet Ontology\n",
    "3. MFO: Molecular Function Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "SAueLJwQQm-4",
    "outputId": "2a025aec-c456-485e-c36c-31d0f50144e8",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='aspect', ylabel='count'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = train_terms['aspect'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwjbuPwjEHJI"
   },
   "source": [
    "**Information Accretion Distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "WvrPhvvy4EmN",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Information Accreation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GO:0000001</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0000002</th>\n",
       "      <td>3.103836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0000003</th>\n",
       "      <td>3.439404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0000011</th>\n",
       "      <td>0.056584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:0000012</th>\n",
       "      <td>6.400377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:2001083</th>\n",
       "      <td>7.159871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:2001084</th>\n",
       "      <td>7.592457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:2001085</th>\n",
       "      <td>7.159871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:2001147</th>\n",
       "      <td>5.554589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GO:2001227</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43248 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Information Accreation\n",
       "GO:0000001                0.000000\n",
       "GO:0000002                3.103836\n",
       "GO:0000003                3.439404\n",
       "GO:0000011                0.056584\n",
       "GO:0000012                6.400377\n",
       "...                            ...\n",
       "GO:2001083                7.159871\n",
       "GO:2001084                7.592457\n",
       "GO:2001085                7.159871\n",
       "GO:2001147                5.554589\n",
       "GO:2001227                0.000000\n",
       "\n",
       "[43248 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 670
    },
    "id": "HN1qxncFDYzT",
    "outputId": "afd2e1d9-6681-42d3-af1c-df21fedb2a6a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(IA_df)\n",
    "# print(IA_df.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequence Lengths of Fasta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_505/3183592557.py:7: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(sequence_lengths, kde = False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeqLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>142246.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>553.636679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>641.728770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>248.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>411.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>654.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>35375.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SeqLen\n",
       "count  142246.000000\n",
       "mean      553.636679\n",
       "std       641.728770\n",
       "min         3.000000\n",
       "25%       248.000000\n",
       "50%       411.000000\n",
       "75%       654.000000\n",
       "max     35375.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sequence_lengths = []\n",
    "reduced_length   = 10001\n",
    "for protein in train_fasta_dict.keys():\n",
    "    length_seq   = len(train_fasta_dict[protein])\n",
    "    sequence_lengths.append(length_seq)\n",
    "    \n",
    "sns.distplot(sequence_lengths, kde = False)\n",
    "pd.DataFrame(sequence_lengths, columns = ['SeqLen']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVokgrnQJyYb"
   },
   "source": [
    "**Likely Direction 25 Apr 2023**\n",
    "1. Since each Gene Ontology has relationships to other gene ontologies, finding a meaningful way to encode the ontology and it's relationships\n",
    "2. Additionally... considering a point of where is too much information since these trees are all theoretically connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your dataframe\n",
    "# Sum across rows for each column (label)\n",
    "# label_sums = train_labels.sum(axis=0)\n",
    "\n",
    "# # Plot the distribution\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.histplot(label_sums, bins=50)\n",
    "# plt.xlabel('Number of Occurrences')\n",
    "# plt.ylabel('Number of Labels')\n",
    "# plt.title('Distribution of Label Occurrences')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-DRnsSfJfw2"
   },
   "source": [
    "# Section 3: Inspecting Ontology Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxgxqUUO9XMk"
   },
   "source": [
    "**Make OBO Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "DmQNrR_A9XMp"
   },
   "outputs": [],
   "source": [
    "# import networkx\n",
    "# knowledge_graph    = networkx.DiGraph()\n",
    "\n",
    "# counter   = 0\n",
    "# for term in gene_ontology.terms():\n",
    "#     if counter < 3:\n",
    "#       knowledge_graph.add_node(term.id)\n",
    "\n",
    "#       #iterate through subclasses\n",
    "#       for subclass in term.subclasses():\n",
    "#           knowledge_graph.add_edge(term.id, subclass)\n",
    "\n",
    "#       #iterate through superclasses\n",
    "#       for superclass in term.superclasses():\n",
    "#           knowledge_graph.add_edge(term.id, superclass)\n",
    "\n",
    "#     counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Fq-lqX9xIImi"
   },
   "outputs": [],
   "source": [
    "# networkx.draw(knowledge_graph, pos=graphviz_layout(knowledge_graph, prog=\"dot\"), with_labels=False, arrows=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "YayjKaz_HyDS"
   },
   "outputs": [],
   "source": [
    "# graphviz_layout(knowledge_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkaQPHqnFCqZ"
   },
   "source": [
    "# Machine Learning Section\n",
    "\n",
    "\n",
    "---\n",
    "1. Every protein has a network of relations with other proteins as seen by the OBO format. \n",
    "2. Go up and down the tree 3 branches and determine if has relationship (encode in a sparse matrix)\n",
    "3. Could Create 4 Dimensional Tensors to represent an ontology and it's superclass and subclass\n",
    "4. Superlcass, Subclass, and Ontology stacked in a another dimensions so that all objects are in one structure\n",
    "5. Think back to tensorflow how we could create a 4D tensor for data preprocessing (images have 3 dims, and then an extra dimension to put them together --> likely could use a similar machine learning technique too. \n",
    "6. Might have to stack a couple nueral networks together... FASTA data needs to be incorporated as well in a meaningful manner\n",
    "7. Predicting the probability of each GO term from sequence and features we extract; multiple GO terms can be associated with a protein.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main WorkFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Tokenizer Gene Ontology Terms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HEQ-J1ZMT7b7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "joined_terms  = train_terms['term'].unique()\n",
    "GO_encoded    = pd.factorize(joined_terms)[0]\n",
    "GO_labels     = pd.factorize(joined_terms)[1]\n",
    "GO_dictionary = {GO_labels[index]: GO_encoded[index] for index in range(len(GO_labels))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One Hot Encoding Targets**\n",
    "1. Necessary for this problem since there's multiple labels that can be assigned to a protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GO_encoder    = OneHotEncoder()\n",
    "GO_dict_array = np.array(list(GO_dictionary.values())).reshape(-1,1)\n",
    "GO_encoder.fit(GO_dict_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "1. All GO's are Targets (Binary Classificaiton Output Layer with len(all gene ontologies)\n",
    "2. Sigmoid activation function telling whether gene ontology is associated with protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory size of my_variable is 5242968 bytes.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Define your variable\n",
    "\n",
    "# Get the memory size of the variable\n",
    "size = sys.getsizeof(train_fasta_dict)\n",
    "\n",
    "print(f\"The memory size of my_variable is {size} bytes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uniprot Protein ID for each Ontology_dict Term\n",
    "with open('protein_seq.pckl', 'rb') as file:\n",
    "    protein_seq = pickle.load(file)\n",
    "\n",
    "# Protein ID extended with gene ontologies\n",
    "with open('ontology_dict.pckl', 'rb') as f:\n",
    "    ontology_dict = pickle.load(f)\n",
    "\n",
    "# GO_dictionary = {}\n",
    "\n",
    "for protein in ontology_dict.keys():\n",
    "    encoded_proteins   =   []\n",
    "    for GO  in list(ontology_dict[protein][0]):\n",
    "        categorized_GO = GO_dictionary[GO]\n",
    "        encoded_proteins.append(categorized_GO)\n",
    "    \n",
    "    ontology_dict[protein] = encoded_proteins   \n",
    "    \n",
    "# Formatting Ontology Dict Compilation Takes 20 Minutes this is faster\n",
    "# ontology_dict = {protein_seq[index]: list(ontology_dict.values())[index] \\\n",
    "#                  for index in range(len(list(ontology_dict.values())))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm -r test_labels.pckl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_embeds.npy', 'test_ids.npy', 'train_embeds.npy', 'train_ids.npy']\n"
     ]
    }
   ],
   "source": [
    "num_of_labels = 1500 \n",
    "\n",
    "with ZipFile('cafa_train_test_embeddings.zip', 'r') as zips:\n",
    "    print(zips.namelist())\n",
    "    with zips.open(zips.namelist()[0]) as file:\n",
    "        x_test = np.load(file)\n",
    "    \n",
    "    with zips.open(zips.namelist()[1]) as file:\n",
    "        y_test = np.load(file)\n",
    "        \n",
    "    with zips.open(zips.namelist()[2]) as file:\n",
    "        x_train = np.load(file)\n",
    "        \n",
    "    with zips.open(zips.namelist()[3]) as file:\n",
    "        y_train = np.load(file)\n",
    "      \n",
    "\n",
    "    \n",
    "# Take value counts in descending order and fetch first 1500 `GO term ID` as labels\n",
    "# labels = train_terms['term'].value_counts().index[:num_of_labels].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Test Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test.to_hdf('test_labels2.h5', 'y_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Embedded Labels (Test or Train)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the Embeddings Using a pretrained Embedding\n",
    "# Nueral Network for Protein Sequences\n",
    "\n",
    "# Creates the Embeddings Using a pretrained Embedding\n",
    "# Nueral Network for Protein Sequences\n",
    "\n",
    "def create_embeddings(data, fasta_dict):\n",
    "    # data: the actual data that needs to be transformed\n",
    "    # fasta_dict: the names for the protein data set for the \n",
    "    \n",
    "    # Filter Most Common Labels\n",
    "    labels             = train_terms['term'].value_counts().index[:num_of_labels].tolist()\n",
    "    \n",
    "    bar                = progressbar.ProgressBar(maxval=num_of_labels, \\\n",
    "    widgets            = [progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "\n",
    "    bar.start()\n",
    "    # Create an empty dataframe of required size for storing the labels,\n",
    "    # i.e, train_size x num_of_labels (142246 x 1500)\n",
    "    train_size         = train_taxonomy.shape[0]    # len(X)\n",
    "    \n",
    "                                           # For some reaosn test_fast_dict is one less than\n",
    "                                           # the test set size\n",
    "            \n",
    "    protein_labels     = np.zeros((train_size ,num_of_labels))\n",
    "\n",
    "    # Convert from numpy to pandas series for better handling\n",
    "    series_protein_ids = pd.Series(train_taxonomy['EntryID'])\n",
    "\n",
    "\n",
    "    # Loop through each label\n",
    "    for i in range(num_of_labels):\n",
    "\n",
    "        # For each label, fetch the corresponding train_terms data\n",
    "        n_train_terms = train_terms[train_terms['term'] ==  labels[i]]\n",
    "        \n",
    "        # Fetch all the unique EntryId aka proteins related to the current label(GO term ID)\n",
    "        label_related_proteins = n_train_terms['EntryID'].unique()\n",
    "\n",
    "        # In the series_train_protein_ids pandas series, if a protein is related\n",
    "        # to the current label, then mark it as 1, else 0.\n",
    "        # Replace the ith column of train_Y with with that pandas series.\n",
    "        \n",
    "#         print(label_related_proteins.shape, series_protein_ids.shape)\n",
    "        protein_labels[:,i] =  series_protein_ids.isin(label_related_proteins).astype(float)\n",
    "\n",
    "        # Progress bar percentage increase\n",
    "        bar.update(i+1)\n",
    "\n",
    "    # Notify the end of progress bar \n",
    "    bar.finish()\n",
    "\n",
    "    # Convert train_Y numpy into pandas dataframe\n",
    "    labels_df = pd.DataFrame(data = protein_labels, columns = labels)\n",
    "\n",
    "    \n",
    "    return labels_df\n",
    "\n",
    "\n",
    "# test_labels   = create_embeddings(y_test, protein_test_labels)\n",
    "# train_labels  = create_embeddings(y_train, protein_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels.to_hdf('train_labels.h5', key = 'y_train', mode = 'w')\n",
    "# test_labels.to_hdf('test_labels.h5',   key = 'y_test',  mode = 'w')\n",
    "\n",
    "train_labels = pd.read_hdf('train_labels.h5')\n",
    "test_labels  = pd.read_hdf('test_labels.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @remote(instance_type=\"ml.g4dn.xlarge\") # Decorator to Use Differnet Instance\n",
    "def nueral_network(dropout, lr, nueronPct, nueronShrinkage):\n",
    "    \n",
    "    history_training[training_count] = []\n",
    "    kfolds = 5\n",
    "    \n",
    "    skf    = KFold(n_splits = kfolds, shuffle = True, random_state = SEED)\n",
    "    \n",
    "    hyperparameters                    = {}\n",
    "    hyperparameters['dropout']         = dropout\n",
    "    hyperparameters['lr']              = lr\n",
    "    hyperparameters['nueronPct']       = nueronPct\n",
    "    hyperparameters['nueronShrinkage'] = nueronShrinkage\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Define A Nueral Network Loop\n",
    "    nueron_max_size       = 5000\n",
    "    nueron_start_size     = int(nueronPct * nueron_max_size)\n",
    "    max_layers            = 20\n",
    "    min_layer_size        = 16\n",
    "    layer_count           = 0\n",
    "    max_layers            = 10\n",
    "    BATCH_SIZE            = 128\n",
    "    \n",
    "    truncated_size        = 2000\n",
    "    \n",
    "    \n",
    "    model       = tf.keras.models.Sequential()\n",
    "    input_layer = tf.keras.layers.Dense(nueron_start_size, input_shape=(x_train.shape[1],),\n",
    "                                       activation = 'relu')\n",
    "    model.add(input_layer)\n",
    "    \n",
    "    while layer_count < max_layers and nueron_start_size > min_layer_size:\n",
    "        \n",
    "        nueron_start_size = int(nueron_start_size * nueronPct)\n",
    "        layer_dense       = tf.keras.layers.Dense(nueron_start_size, activation = 'relu')\n",
    "        model.add(layer_dense)\n",
    "        \n",
    "        layer_count      += 1\n",
    "        \n",
    "        \n",
    "    final_layer        = tf.keras.layers.Dense(y_train.shape[1], activation ='sigmoid')\n",
    "    model.add(final_layer)\n",
    "    \n",
    "    AdamOpt            = Adam(learning_rate = hyperparameters['lr'])\n",
    "    model.compile(metrics = 'binary_crossentropy', optimizer = AdamOpt, \n",
    "                                          loss = 'binary_crossentropy')\n",
    "    \n",
    "    history            = model.fit(x_train[:truncated_size], y_train[:truncated_size],\n",
    "                            epochs = 4, batch_size = BATCH_SIZE)\n",
    "    \n",
    "    history_training[training_count].append(history)\n",
    "    \n",
    "    predictions        = model.predict(x_test)\n",
    "    y_test_trunc       = np.array(y_test)\n",
    "    \n",
    "    scores_matrix      = np.zeros(shape = (predictions.shape[0], predictions.shape[1]))\n",
    "    scores_per_protein = np.zeros(shape = (predictions.shape[0]))\n",
    "    \n",
    "    \n",
    "    # Analyze Accuracy Element By Elemnt\n",
    "    # Assign Accuracy per protein\n",
    "#     print(predictions.shape[0]-1, y_test_trunc.shape[0])\n",
    "    bar                = progressbar.ProgressBar(maxval=predictions.shape[0], \\\n",
    "    widgets            = [progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "    bar.start()\n",
    "\n",
    "    # Print available memory in GB\n",
    "    print(f\"Available Memory: {mem.available / (1024 ** 3)} GB\")\n",
    "    \n",
    "    for pred in range(predictions.shape[0]-1):\n",
    "        for item in range(predictions.shape[1]):\n",
    "            equality = (y_test_trunc[pred][item] == predictions[pred][item])\n",
    "            scores_matrix[pred][item] = equality\n",
    "            \n",
    "        total_entries = scores_matrix.shape[1]\n",
    "        total_correct = np.count_nonzero(scores_matrix[pred])\n",
    "        accuracy      = total_correct / total_entries\n",
    "        \n",
    "        scores_per_protein[pred] = accuracy\n",
    "        bar.update(pred+1)\n",
    "\n",
    "    # Notify the end of progress bar \n",
    "    bar.finish()\n",
    "    \n",
    "    # Assign Total Accuracy\n",
    "    total_accuracy  = np.average(scores_per_protein)\n",
    "        \n",
    "    \n",
    "    return total_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Call Hyperparameter Optimization... GPU would likely help**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_training = {}\n",
    "# training_count   = 0\n",
    "\n",
    "# pbounds          = {\n",
    "#                  'dropout': (0.0, 0.5),\n",
    "#                  'lr': (0.001, 0.1),\n",
    "#                  'nueronPct': (0.1, 1),\n",
    "#                  'nueronShrinkage': (0.1, 1)\n",
    "#                  }\n",
    "\n",
    "# SEED             = 1234\n",
    "\n",
    "# optimizer = BayesianOptimization(\n",
    "#     f = nueral_network,\n",
    "#     pbounds = pbounds,\n",
    "#     verbose = 2,\n",
    "#     random_state = SEED\n",
    "# )\n",
    "\n",
    "# optimizer.maximize(init_points = 1, n_iter = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_yktlhR6gD3"
   },
   "source": [
    "# Section 4: Ngrams Sequence Model Training Approach\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYoyUN9HtvCE"
   },
   "source": [
    "**Transform Tokenizing Dict for 3 Letter Amino Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Memory: 15.324687957763672 GB\n",
      "Available Memory: 10.309249877929688 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Get memory usage information in bytes\n",
    "mem = psutil.virtual_memory()\n",
    "\n",
    "# Print total memory in GB\n",
    "print(f\"Total Memory: {mem.total / (1024 ** 3)} GB\")\n",
    "\n",
    "# Print available memory in GB\n",
    "print(f\"Available Memory: {mem.available / (1024 ** 3)} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ProtTrans Protein Language Model Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==2.0.0+cpu torchvision==0.15.0+cpu -f https://download.pytorch.org/whl/cpu/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding X variable (Training Sequences) Into More Meantingful Pretrained NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import T5Tokenizer, T5EncoderModel\n",
    "# import torch\n",
    "\n",
    "# device    = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Load the tokenizer\n",
    "# tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
    "\n",
    "# # Load the model\n",
    "# model     = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\")\n",
    "\n",
    "# # only GPUs support half-precision currently; if you want to run on CPU use full-precision (not recommended, much slower)\n",
    "# # model.full() if device=='cpu' else model.half()\n",
    "\n",
    "# if device.type=='cpu':\n",
    "#     model = model.float()\n",
    "# else:\n",
    "#     model = model.half()\n",
    "\n",
    "# # prepare your protein sequences as a list\n",
    "# sequence_examples = list(train_fasta_dict.values())\n",
    "\n",
    "# # replace all rare/ambiguous amino acids by X and introduce white-space between all amino acids\n",
    "# max_length        = 1500\n",
    "# sequence_examples = [\" \".join(list(re.sub(r\"[UZOB]\", \"X\", sequence))) for sequence in sequence_examples]\n",
    "\n",
    "# sequence_examples = [sequence[:max_length] for sequence in sequence_examples]\n",
    "\n",
    "# # set batch size\n",
    "# batch_size = 16\n",
    "# batches    = [sequence_examples[i:i + batch_size] for i in range(0, len(sequence_examples), batch_size)]\n",
    "\n",
    "# embeddings = []\n",
    "\n",
    "# for batch in batches:\n",
    "#     # tokenize sequences and pad up to the longest sequence in the batch\n",
    "#     ids = tokenizer.batch_encode_plus(batch, add_special_tokens=True, padding='max_length', max_length = 1500)\n",
    "\n",
    "#     input_ids      = torch.tensor(ids['input_ids']).to(device)\n",
    "#     attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
    "\n",
    "#     # generate embeddings\n",
    "#     with torch.no_grad():\n",
    "#         embedding_repr = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        \n",
    "#     # per-protein embeddings by taking the mean along sequence dimension\n",
    "#     per_protein_embeddings = embedding_repr.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "    \n",
    "#     embeddings.append(per_protein_embeddings)\n",
    "\n",
    "# # concatenate all embeddings\n",
    "# embeddings = np.concatenate(embeddings)\n",
    "\n",
    "# # tokenize sequences and pad up to the longest sequence in the batch\n",
    "# ids = tokenizer.batch_encode_plus(sequence_examples, add_special_tokens=True, padding=\"longest\")\n",
    "\n",
    "# input_ids      = torch.tensor(ids['input_ids']).to(device)\n",
    "# attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
    "\n",
    "# # generate embeddings\n",
    "# with torch.no_grad():\n",
    "#     embedding_rpr = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "\n",
    "# # extract residue embeddings for the first ([0,:]) sequence in the batch and remove padded & special tokens ([0,:7]) \n",
    "# emb_0 = embedding_repr.last_hidden_state[0,:7] # shape (7 x 1024)\n",
    "# # same for the second ([1,:]) sequence but taking into account different sequence lengths ([1,:8])\n",
    "# emb_1 = embedding_repr.last_hidden_state[1,:8] # shape (8 x 1024)\n",
    "\n",
    "# # if you want to derive a single representation (per-protein embedding) for the whole protein\n",
    "# emb_0_per_protein = emb_0.mean(dim=0) # shape (1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embedding using Facebooks ESM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.0.0)\n",
      "Collecting fairseq\n",
      "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.7.2)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n",
      "Requirement already satisfied: cmake in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.27.2)\n",
      "Requirement already satisfied: lit in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: cffi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fairseq) (1.15.1)\n",
      "Requirement already satisfied: cython in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fairseq) (0.29.34)\n",
      "Collecting hydra-core<1.1,>=1.0.7 (from fairseq)\n",
      "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting omegaconf<2.1 (from fairseq)\n",
      "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fairseq) (2023.5.5)\n",
      "Collecting sacrebleu>=1.4.12 (from fairseq)\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fairseq) (4.65.0)\n",
      "Requirement already satisfied: bitarray in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fairseq) (2.7.3)\n",
      "Collecting torchaudio>=0.8.0 (from fairseq)\n",
      "  Downloading torchaudio-2.0.2-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fairseq) (1.22.3)\n",
      "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq)\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from omegaconf<2.1->fairseq) (5.4.1)\n",
      "Collecting portalocker (from sacrebleu>=1.4.12->fairseq)\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu>=1.4.12->fairseq)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: colorama in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (0.4.3)\n",
      "Collecting lxml (from sacrebleu>=1.4.12->fairseq)\n",
      "  Downloading lxml-4.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m132.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch\n",
      "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from cffi->fairseq) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
      "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=10390748 sha256=f625da1ad7846c14385550c4d0b12ea5443bc2d5fd735a9dfc9c0e8d5e2d2216\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=c8ba8c4aa17abe1e655b51ecca3c5b6e1b2c380b6207ece8aafa80dddbd892db\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
      "Successfully built fairseq antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, tabulate, portalocker, omegaconf, lxml, sacrebleu, hydra-core, torch, torchaudio, fairseq\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.0\n",
      "    Uninstalling torch-2.0.0:\n",
      "      Successfully uninstalled torch-2.0.0\n",
      "Successfully installed antlr4-python3-runtime-4.8 fairseq-0.12.2 hydra-core-1.0.7 lxml-4.9.3 omegaconf-2.0.6 portalocker-2.7.0 sacrebleu-2.3.1 tabulate-0.9.0 torch-2.0.1 torchaudio-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Looking in links: https://download.pytorch.org/whl/cu110/torch_stable.html\n",
      "Collecting torch==2.0.0\n",
      "  Using cached torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (67.7.2)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.40.0)\n",
      "Requirement already satisfied: cmake in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.0) (3.27.2)\n",
      "Requirement already satisfied: lit in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.0) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch==2.0.0) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch==2.0.0) (1.3.0)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1\n",
      "    Uninstalling torch-2.0.1:\n",
      "      Successfully uninstalled torch-2.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.0.2 requires torch==2.0.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.0.0 -f https://download.pytorch.org/whl/cu110/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-08-20 16:24:29--  https://dl.fbaipublicfiles.com/fair-esm/models/esm1b_t33_650M_UR50S.pt\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.165.83.79, 18.165.83.35, 18.165.83.44, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.165.83.79|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -c https://dl.fbaipublicfiles.com/fair-esm/models/esm1b_t33_650M_UR50S.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting fair-esm\n",
      "  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fair-esm\n",
      "Successfully installed fair-esm-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fair-esm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data        = {}\n",
    "prot_labels = list(train_fasta_dict.values())\n",
    "for index in range(len(protein_train_labels)):\n",
    "    data[protein_train_labels[index]] = prot_labels[index]\n",
    "    \n",
    "data        = list(data.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Convert sequences to model input\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m batch_labels, batch_strs, batch_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_converter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Get embeddings\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/esm/data.py:266\u001b[0m, in \u001b[0;36mBatchConverter.__call__\u001b[0;34m(self, raw_batch)\u001b[0m\n\u001b[1;32m    265\u001b[0m batch_labels, seq_str_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mraw_batch)\n\u001b[0;32m--> 266\u001b[0m seq_encoded_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphabet\u001b[38;5;241m.\u001b[39mencode(seq_str) \u001b[38;5;28;01mfor\u001b[39;00m seq_str \u001b[38;5;129;01min\u001b[39;00m seq_str_list]\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncation_seq_length:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/esm/data.py:266\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    265\u001b[0m batch_labels, seq_str_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mraw_batch)\n\u001b[0;32m--> 266\u001b[0m seq_encoded_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malphabet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_str\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m seq_str \u001b[38;5;129;01min\u001b[39;00m seq_str_list]\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncation_seq_length:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/esm/data.py:250\u001b[0m, in \u001b[0;36mAlphabet.encode\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtok_to_idx[tok] \u001b[38;5;28;01mfor\u001b[39;00m tok \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/esm/data.py:246\u001b[0m, in \u001b[0;36mAlphabet.tokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m no_split_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_no_split_tokens\n\u001b[0;32m--> 246\u001b[0m tokenized_text \u001b[38;5;241m=\u001b[39m \u001b[43msplit_on_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_split_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenized_text\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/esm/data.py:234\u001b[0m, in \u001b[0;36mAlphabet.tokenize.<locals>.split_on_tokens\u001b[0;34m(tok_list, text)\u001b[0m\n\u001b[1;32m    232\u001b[0m     text_list \u001b[38;5;241m=\u001b[39m tokenized_text\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique_no_split_tokens\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtokenized_text\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/esm/data.py:236\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    232\u001b[0m     text_list \u001b[38;5;241m=\u001b[39m tokenized_text\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    235\u001b[0m     itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m--> 236\u001b[0m         (\n\u001b[1;32m    237\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenize(token)\n\u001b[1;32m    238\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_no_split_tokens\n\u001b[1;32m    239\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m [token]\n\u001b[1;32m    240\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokenized_text\n\u001b[1;32m    241\u001b[0m         )\n\u001b[1;32m    242\u001b[0m     )\n\u001b[1;32m    243\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import esm\n",
    "\n",
    "# Load ESM-1b model\n",
    "model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "# Convert sequences to model input\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "\n",
    "# Get embeddings\n",
    "all_results = []\n",
    "bar                = progressbar.ProgressBar(maxval=len(data), \\\n",
    "widgets            = [progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "bar.start()\n",
    "counter            = 0 \n",
    "with torch.no_grad():\n",
    "    \n",
    "    \n",
    "    results = model(batch_tokens, repr_layers=[33], return_contacts=False)\n",
    "    all_results.append(results)\n",
    "    \n",
    "    coun\n",
    "    bar.update(counter+1)\n",
    "\n",
    "    # Notify the end of progress bar \n",
    "bar.finish()\n",
    "    \n",
    "    \n",
    "# Extract the representation from layer 33 for the first protein\n",
    "token_representations = results[\"representations\"][33]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# input_dim     = [x_train.shape[1]]   # 8000 Biological Work Combinations 20^3 (20 Aminos) + OOV + IDK\n",
    "embedding_dim = 16\n",
    "\n",
    "input_dim     = (x_train.shape[1],)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.BatchNormalization(input_shape=input_dim),    \n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.7),\n",
    "    tf.keras.layers.Dense(units = 32, activation = 'relu'),\n",
    "#     tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.7),\n",
    "    tf.keras.layers.Dense(units=num_of_labels, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     # Start with 1D Convolutional layers\n",
    "#     tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1), input_shape=input_dim),\n",
    "#     tf.keras.layers.Conv1D(64, kernel_size=5, activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    \n",
    "#     tf.keras.layers.Conv1D(64, kernel_size=5, activation='relu'),\n",
    "#     tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "\n",
    "#     # Flattening the 1D convolutional output to feed it to dense layers\n",
    "#     tf.keras.layers.Flatten(),\n",
    "    \n",
    "#     # Follow with Dense layers as per your original design\n",
    "#     tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "#     tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.25),\n",
    "#     tf.keras.layers.Dense(units=num_of_labels, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "\n",
    "optimizer               = tf.keras.optimizers.Adam(learning_rate = 0.00005)\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Add, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models       import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks    import EarlyStopping\n",
    "\n",
    "def residual_block(data, filters, d_rate):\n",
    "\n",
    "    shortcut = data\n",
    "\n",
    "    bn1 = tf.keras.layers.BatchNormalization()(data)\n",
    "    act1 = Activation('relu')(bn1)\n",
    "    conv1 = Conv1D(filters, 1, dilation_rate=d_rate, padding='same', kernel_regularizer=l2(0.001))(act1)\n",
    "\n",
    "    #bottleneck convolution\n",
    "    bn2 = BatchNormalization()(conv1)\n",
    "    act2 = Activation('relu')(bn2)\n",
    "    conv2 = Conv1D(filters, 3, padding='same', kernel_regularizer=l2(0.001))(act2)\n",
    "\n",
    "    #skip connection\n",
    "    x = Add()([conv2, shortcut])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = tf.keras.layers.Input(shape=(x_train.shape[1],1))\n",
    "\n",
    "#initial conv\n",
    "conv = tf.keras.layers.Conv1D(64, 1, padding='same')(x_input) \n",
    "\n",
    "# per-residue representation\n",
    "res1 = residual_block(conv, 64, 2)\n",
    "res2 = residual_block(res1, 64, 3)\n",
    "\n",
    "x    = tf.keras.layers.MaxPooling1D(3)(res2)\n",
    "x    = Dropout(0.5)(x)\n",
    "\n",
    "# softmax classifier\n",
    "x    = Flatten()(x)\n",
    "x_output = Dense(1500, activation='sigmoid', kernel_regularizer=l2(0.0001))(x)\n",
    "\n",
    "model_CNN = Model(inputs=x_input, outputs=x_output)\n",
    "model_CNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "model_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "history = model_CNN.fit(\n",
    "    x_train, np.array(train_labels),\n",
    "    epochs=10, batch_size=64,\n",
    "    validation_split = 0.2,\n",
    "    callbacks=[es]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @remote(instance_type=\"ml.g4dn.xlarge\") # Decorator to Use Differnet Instance\n",
    "def train_nueral_net():\n",
    "    epochs             = 20\n",
    "    batch_size         = 32\n",
    "\n",
    "    history            = model.fit(x_train, np.array(train_labels), epochs = epochs, \\\n",
    "                         batch_size = batch_size, validation_split = 0.2, verbose = 1)\n",
    "    \n",
    "    return history, model\n",
    "\n",
    "# history, model = train_nueral_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_pred = pd.DataFrame(predictions)\n",
    "pd_pred[2].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions        =  model.predict(x_test)\n",
    "y_test             =  np.array(test_labels)\n",
    "\n",
    "# scores_matrix      = np.zeros(shape = (predictions.shape[0], predictions.shape[1]))\n",
    "# scores_per_protein = np.zeros(shape = (predictions.shape[0]))\n",
    "\n",
    "# bar                = progressbar.ProgressBar(maxval=predictions.shape[0], \\\n",
    "# widgets            = [progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "# bar.start()\n",
    "\n",
    "# for pred in range(predictions.shape[0]-1):\n",
    "#     for item in range(predictions.shape[1]):\n",
    "        \n",
    "#         equality = (y_test[pred][item] == predictions[pred][item])\n",
    "#         scores_matrix[pred][item] = equality\n",
    "\n",
    "#     total_entries = scores_matrix.shape[1]\n",
    "#     total_correct = np.count_nonzero(scores_matrix[pred])\n",
    "#     accuracy      = total_correct / total_entries\n",
    "\n",
    "#     scores_per_protein[pred] = accuracy\n",
    "#     bar.update(pred+1)\n",
    "\n",
    "# # Notify the end of progress bar \n",
    "# bar.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @remote(instance_type=\"ml.r5.2xlarge\") # Decorator to Use Differnet Instance\n",
    "def create_submission_df():\n",
    "    \n",
    "    GO_labels           = train_terms['term'].value_counts().index[:num_of_labels].tolist()\n",
    "\n",
    "    predictions_df      = pd.DataFrame(predictions[:-1], index=protein_test_labels, columns=GO_labels)\n",
    "    final_submission_df = predictions_df.reset_index().melt(id_vars='index', var_name='GO_labels', value_name='predictions')\n",
    "    \n",
    "#     final_submission_df   = pd.DataFrame()\n",
    "#     predictions_df = pd.DataFrame(predictions[:-1], index = protein_test_labels, columns = GO_labels)\n",
    "    \n",
    "#     for index in predictions_df.index:\n",
    "#         final_submission_df = pd.concat([final_submission_df, predictions_df.loc[index]])\n",
    "    \n",
    "    return final_submission_df\n",
    "\n",
    "submission = create_submission_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_proteins = submission['index'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_submission = pd.DataFrame()\n",
    "# sort_submission['']\n",
    "\n",
    "def sort_submission(submission):\n",
    "\n",
    "    submission   = submission.sort_values(by = 'index')\n",
    "        \n",
    "    return submission\n",
    "\n",
    "\n",
    "sorted_submission = sort_submission(submission)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_submission.to_hdf('submission_draft.h5', key = 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_submission = pd.read_hdf('submission_draft.h5', key = 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_submission.to_csv('submission.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_s3_file(file_name):\n",
    "    \n",
    "    file_name = file_name\n",
    "    \n",
    "    return\n",
    "\n",
    "s3        = boto3.resource('s3')\n",
    "# file_name = 't5embeds.zip'\n",
    "# y_train   = 'labels_df.pckl'\n",
    "s3.meta.client.upload_file('submission.tsv', bucket_name, 'submission.tsv')\n",
    "# s3.meta.client.upload_file('labels_df.h5',   bucket_name, 'labels_df.h5')\n",
    "\n",
    "# s3.meta.client.upload_file('train_labels.h5', bucket_name, 'train_labels.h5')\n",
    "# s3.meta.client.upload_file('test_labels.h5', bucket_name, 'test_labels.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(scores_per_protein).plot(kind = 'box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXT3GDC_W6IL"
   },
   "source": [
    "# Protein-Bert Model Creation\n",
    "\n",
    "---\n",
    "1. Need to tokenize amino acids (0-19).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5-1ek1hyXmo",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install protein-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzwRzoJ0XEio",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajiby-fKc-jl"
   },
   "source": [
    "**Pre Trained Model Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rc7wndodc4Mo",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "05b13017-3cb9-4b15-bc43-7d5db06072ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget ftp://ftp.cs.huji.ac.il/users/nadavb/protein_bert/epoch_92400_sample_23500000.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SdOBXuuFnU9"
   },
   "source": [
    "**Tokenize Each Amino Acid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqflIxsADdsg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Amino_tokenizer  = Tokenizer(char_level = True)\n",
    "joined_sequences = list(train_fasta_dict.values())[0:10001]\n",
    "Amino_tokenizer.fit_on_texts(joined_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JmG7mGsdCjr"
   },
   "source": [
    "**Creating the Model**\n",
    "1. Protein Bert Takes in Amino Acids Seq as Input because the tokenizing has to match up with the original tokenization it was trained on\n",
    "2. The Output settings at the beginning must adjusted to the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ayvgj6WX9VB"
   },
   "outputs": [],
   "source": [
    "BENCHMARK_NAME = 'signalP_binary'\n",
    "\n",
    "# A local (non-global) binary output\n",
    "OUTPUT_TYPE    = OutputType(False, 'categorical')  # Categorical Gene ONtologies\n",
    "UNIQUE_LABELS  = range(10001)                      # Tokenizer Terms 10001\n",
    "OUTPUT_SPEC    = OutputSpec(OUTPUT_TYPE, UNIQUE_LABELS)\n",
    "\n",
    "\n",
    "# train_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.train.csv' % BENCHMARK_NAME)\n",
    "# train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "x_train, x_val, y_train, y_val = train_test_split(joined_sequences, go_encoded, test_size = 0.15, random_state = 0)\n",
    "\n",
    "# test_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.test.csv' % BENCHMARK_NAME)\n",
    "# test_set = pd.read_csv(test_set_file_path).dropna().drop_duplicates()\n",
    "\n",
    "# print(f'{len(train_set)} training set records, {len(valid_set)} validation set records, {len(test_set)} test set records.')\n",
    "\n",
    "\n",
    "# Loading the pre-trained model and fine-tuning it on the loaded dataset\n",
    "\n",
    "pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "\n",
    "# get_model_with_hidden_layers_as_outputs gives the model output access to the hidden layers (on top of the output)\n",
    "model_generator = FinetuningModelGenerator(pretrained_model_generator, OUTPUT_SPEC, pretraining_model_manipulation_function = \\\n",
    "        get_model_with_hidden_layers_as_outputs, dropout_rate = 0.5)\n",
    "\n",
    "training_callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(patience = 1, factor = 0.25, min_lr = 1e-05, verbose = 1),\n",
    "    keras.callbacks.EarlyStopping(patience = 2, restore_best_weights = True),\n",
    "]\n",
    "\n",
    "finetune(model_generator, input_encoder, OUTPUT_SPEC, x_train, y_train, x_val, y_val, \\\n",
    "        seq_len = 512, batch_size = 16, max_epochs_per_stage = 40, lr = 1e-04, begin_with_frozen_pretrained_layers = True, \\\n",
    "        lr_with_frozen_pretrained_layers = 1e-02, n_final_epochs = 1, final_seq_len = 1024, final_lr = 1e-05, callbacks = training_callbacks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqox9E6dYio6"
   },
   "outputs": [],
   "source": [
    "# Evaluating the performance on the test-set\n",
    "\n",
    "results, confusion_matrix = evaluate_by_len(model_generator, input_encoder, OUTPUT_SPEC, test_fasta_dict, test_se, \\\n",
    "        start_seq_len = 512, start_batch_size = 32)\n",
    "\n",
    "print('Test-set performance:')\n",
    "display(results)\n",
    "\n",
    "print('Confusion matrix:')\n",
    "display(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m108"
  },
  "gpuClass": "standard",
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
